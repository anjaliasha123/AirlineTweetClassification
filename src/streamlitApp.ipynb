{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "streamlitApp.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMF6vJNwASiJM0wOKGfmGAN"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lhayc5ZuL6r",
        "outputId": "e3bac417-fcd1-4283-c551-0da8ec6d6142"
      },
      "source": [
        "!pip install streamlit -q"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8.3 MB 6.7 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 111 kB 58.3 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 180 kB 56.9 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 76 kB 6.1 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4.3 MB 43.0 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63 kB 2.2 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125 kB 61.3 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 790 kB 33.6 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 374 kB 44.5 MB/s \n",
            "\u001b[?25h  Building wheel for blinker (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "jupyter-console 5.2.0 requires prompt-toolkit<2.0.0,>=1.0.0, but you have prompt-toolkit 3.0.21 which is incompatible.\n",
            "google-colab 1.0.0 requires ipykernel~=4.10, but you have ipykernel 6.5.0 which is incompatible.\n",
            "google-colab 1.0.0 requires ipython~=5.5.0, but you have ipython 7.29.0 which is incompatible.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gQqmie_tsce",
        "outputId": "2e5119e9-be12-4413-c164-50f0e2357796"
      },
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import plotly.express as px\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "import matplotlib.pyplot as plt\n",
        "st.title(\"Sentiment Analysis of Tweets About US Airlines\")\n",
        "st.sidebar.title(\"Sentiment Analysis of Tweets About US Airlines\")\n",
        "st.markdown(\"Sentiment Analysis Application‚úàÔ∏è \")\n",
        "st.sidebar.markdown(\"Click sidebar elemnts to view \")\n",
        "data_url = (\"https://raw.githubusercontent.com/anjaliasha123/Data_Visualization_projects/master/Streamlit_python/Tweets.csv\")\n",
        "@st.cache\n",
        "def load_data():\n",
        "    data = pd.read_csv(data_url)\n",
        "    data['tweet_created'] = pd.to_datetime(data['tweet_created'])\n",
        "    return data\n",
        "data = load_data()\n",
        "st.subheader(\"Random Tweets\")\n",
        "random_tweet = st.radio('Sentiment',('positive','neutral','negative'))\n",
        "st.markdown(data.query('airline_sentiment==@random_tweet')[['text']].sample(n=1).iat[0,0])\n",
        "\n",
        "\n",
        "st.sidebar.markdown(\"Visualizing the sentiments\")\n",
        "select = st.sidebar.selectbox('Type of Chart!',['histogram','pie-chart'], key=1)\n",
        "sentiment_count = data['airline_sentiment'].value_counts()\n",
        "\n",
        "sentiment_count = pd.DataFrame({'Sentiment':sentiment_count.index, 'Tweets':sentiment_count.values})\n",
        "if not st.sidebar.checkbox(\"Hide\", True):\n",
        "    st.markdown(\"## Number of tweets by sentiment\")\n",
        "    if select == 'histogram':\n",
        "        fig = px.bar(sentiment_count,x='Sentiment',y='Tweets', color='Tweets',height=500)\n",
        "        st.plotly_chart(fig)\n",
        "\n",
        "    else:\n",
        "        fig = px.pie(sentiment_count,values='Tweets',names='Sentiment')\n",
        "        st.plotly_chart(fig)\n",
        "        \n",
        "st.set_option('deprecation.showPyplotGlobalUse', False)\n",
        "\n",
        "\n",
        "import tensorflow\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "def predict(text):\n",
        "  modelP = tensorflow.keras.models.load_model(\"bilstmCNNTweetNew.h5\")\n",
        "  tok = Tokenizer(num_words =10000,filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True)\n",
        "  tok.fit_on_texts(data.text.values)\n",
        "  sequences = tok.texts_to_sequences(data.text.values)\n",
        "  word_index = tok.word_index\n",
        "  X_data = pad_sequences(sequences, maxlen = 100)\n",
        "  t = [text]\n",
        "  seq = tok.texts_to_sequences(t)\n",
        "  padded = pad_sequences(seq, maxlen=100)\n",
        "  pred = modelP.predict(padded)\n",
        "  labels = ['positive', 'negative','neutral']\n",
        "  label = labels[np.argmax(pred)]\n",
        "  percent = np.max(pred) * 100\n",
        "  st.write('Predicted Sentiment: '+label)\n",
        "  st.write('Confident:'+str(percent)+'%')\n",
        "\n",
        "st.sidebar.header(\"Check out new tweets!üòé\")\n",
        "if not st.sidebar.checkbox(\"Hide\", True, key=10):\n",
        "  text = st.text_input('Tweet', '')\n",
        "  st.button('Predict Sentiment',on_click=predict(text))\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYOe9ZYevCAK"
      },
      "source": [
        "!streamlit run app.py & npx localtunnel --port 8501"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9slPWwgAv2fi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}