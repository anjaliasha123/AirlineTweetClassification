{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "streamlitApp.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOTyEclVeAnEjq+bVKdPfxU"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lhayc5ZuL6r",
        "outputId": "eb6977b4-4d74-4654-cccc-a2af728bde2b"
      },
      "source": [
        "!pip install streamlit -q"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8.3 MB 14.6 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111 kB 56.1 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 180 kB 61.3 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 76 kB 4.9 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.3 MB 57.9 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 63 kB 1.5 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 124 kB 65.8 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 788 kB 59.1 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 374 kB 51.0 MB/s \n",
            "\u001b[?25h  Building wheel for blinker (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "jupyter-console 5.2.0 requires prompt-toolkit<2.0.0,>=1.0.0, but you have prompt-toolkit 3.0.21 which is incompatible.\n",
            "google-colab 1.0.0 requires ipykernel~=4.10, but you have ipykernel 6.4.2 which is incompatible.\n",
            "google-colab 1.0.0 requires ipython~=5.5.0, but you have ipython 7.28.0 which is incompatible.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gQqmie_tsce",
        "outputId": "cf361060-aebb-4557-b264-ea10b3157c3c"
      },
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import plotly.express as px\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "import matplotlib.pyplot as plt\n",
        "st.title(\"Sentiment Analysis of Tweets About US Airlines\")\n",
        "st.sidebar.title(\"Sentiment Analysis of Tweets About US Airlines\")\n",
        "st.markdown(\"Sentiment Analysis Applicationâœˆï¸ \")\n",
        "st.sidebar.markdown(\"Click sidebar elemnts to view \")\n",
        "data_url = (\"https://raw.githubusercontent.com/anjaliasha123/Data_Visualization_projects/master/Streamlit_python/Tweets.csv\")\n",
        "@st.cache\n",
        "def load_data():\n",
        "    data = pd.read_csv(data_url)\n",
        "    data['tweet_created'] = pd.to_datetime(data['tweet_created'])\n",
        "    return data\n",
        "data = load_data()\n",
        "#to display the Tweets\n",
        "#st.write(data)\n",
        "st.subheader(\"Random Tweets\")\n",
        "random_tweet = st.radio('Sentiment',('positive','neutral','negative'))\n",
        "st.markdown(data.query('airline_sentiment==@random_tweet')[['text']].sample(n=1).iat[0,0])\n",
        "\n",
        "\n",
        "st.sidebar.markdown(\"Visualizing the sentiments\")\n",
        "select = st.sidebar.selectbox('Type of Chart!',['histogram','pie-chart'], key=1)\n",
        "sentiment_count = data['airline_sentiment'].value_counts()\n",
        "\n",
        "sentiment_count = pd.DataFrame({'Sentiment':sentiment_count.index, 'Tweets':sentiment_count.values})\n",
        "if not st.sidebar.checkbox(\"Hide\", True):\n",
        "    st.markdown(\"## Number of tweets by sentiment\")\n",
        "    if select == 'histogram':\n",
        "        fig = px.bar(sentiment_count,x='Sentiment',y='Tweets', color='Tweets',height=500)\n",
        "        st.plotly_chart(fig)\n",
        "\n",
        "    else:\n",
        "        fig = px.pie(sentiment_count,values='Tweets',names='Sentiment')\n",
        "        st.plotly_chart(fig)\n",
        "        \n",
        "st.set_option('deprecation.showPyplotGlobalUse', False)\n",
        "\n",
        "st.sidebar.subheader(\"Tweets by Airlines\")\n",
        "choice = st.sidebar.multiselect('Pick airlines',('US Airways','United','American','Southwest','Delta','Virgin America'), key=0)\n",
        "\n",
        "if len(choice)>0:\n",
        "    choice_data = data[data.airline.isin(choice)]\n",
        "    fig_choice = px.histogram(choice_data, x='airline',y='airline_sentiment',histfunc='count',color='airline_sentiment',facet_col='airline_sentiment',labels={'airline_sentiment':'tweets'},height=800,width=600)\n",
        "    st.plotly_chart(fig_choice)\n",
        "\n",
        "st.sidebar.header(\"Word Cloud\")\n",
        "word_sentiment = st.sidebar.radio('Sentiment Word Cloud',('positive','neutral','negative'))\n",
        "if not st.sidebar.checkbox(\"Close\",True,key='3'):\n",
        "    st.subheader(\"Word Cloud for %s sentiment\"%(word_sentiment))\n",
        "    df = data[data['airline_sentiment']==word_sentiment]\n",
        "    words = ' '.join(df['text'])\n",
        "    pro_words = ' '.join([word for word in words.split() if 'http' not in word and not word.startswith('@') and word!= 'RT'])\n",
        "    wordcloud = WordCloud(stopwords=STOPWORDS, background_color='white',height=640,width=640).generate(pro_words)\n",
        "    plt.imshow(wordcloud)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    st.pyplot()\n",
        "\n",
        "import tensorflow\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "def predict(text):\n",
        "  modelP = tensorflow.keras.models.load_model(\"tweetModel.h5\")\n",
        "  tok = Tokenizer(num_words =10000,filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True)\n",
        "  tok.fit_on_texts(data.text.values)\n",
        "  sequences = tok.texts_to_sequences(data.text.values)\n",
        "  word_index = tok.word_index\n",
        "  X_data = pad_sequences(sequences, maxlen = 100)\n",
        "  t = [text]\n",
        "  seq = tok.texts_to_sequences(t)\n",
        "  padded = pad_sequences(seq, maxlen=100)\n",
        "  pred = modelP.predict(padded)\n",
        "  labels = ['positive', 'negative','neutral']\n",
        "  label = labels[np.argmax(pred)]\n",
        "  percent = max(pred) * 100\n",
        "  st.write('Predicted Sentiment: '+label)\n",
        "  st.write('Confident:'+str(percent))\n",
        "\n",
        "st.sidebar.header(\"Check out new tweets!ðŸ˜Ž\")\n",
        "if not st.sidebar.checkbox(\"Hide\", True, key=10):\n",
        "  text = st.text_input('Tweet', 'Airline sentiment tweets')\n",
        "  st.button('Predict Sentiment',on_click=predict(text))\n",
        "\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYOe9ZYevCAK"
      },
      "source": [
        "!streamlit run app.py & npx localtunnel --port 8501"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9slPWwgAv2fi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}