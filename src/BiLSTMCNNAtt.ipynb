{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BiLSTMCNNAtt.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1CCdrQjSMwaPeprd_7ezcjONE3t_9_Un-",
      "authorship_tag": "ABX9TyPoLFoUuiUG7WFn67nFaaWl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anjaliasha123/AirlineTweetClassification/blob/main/src/BiLSTMCNNAtt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJ-w_DdPm7-_",
        "outputId": "4b83220c-f15b-4b3c-c0f0-368241136633"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xjTDSlgsKUx"
      },
      "source": [
        "Initial required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zgZ4NdRswRG"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1evzfj8A0ix7"
      },
      "source": [
        "#intializing global variables\n",
        "data = pd.read_csv('https://raw.githubusercontent.com/anjaliasha123/Data_Visualization_projects/master/Streamlit_python/Tweets.csv')\n",
        "Xdata = data[['airline_sentiment_confidence','airline','text','latitude','longitude']]\n",
        "Ydata = data['airline_sentiment']"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_c8Y9f-380M"
      },
      "source": [
        "#suffling the data and forming a balanced data set\n",
        "num_tweets_per_category = 2363\n",
        "shuffled = data.reindex(np.random.permutation(data.index))\n",
        "positive = shuffled[shuffled['airline_sentiment'] == 'positive'][:num_tweets_per_category]\n",
        "negative = shuffled[shuffled['airline_sentiment'] == 'negative'][:num_tweets_per_category]\n",
        "neutral  = shuffled[shuffled['airline_sentiment'] == 'neutral'][:num_tweets_per_category]\n",
        "data  = pd.concat([positive,negative,neutral], ignore_index=True)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2zwS1SI6slu"
      },
      "source": [
        "Xdata = data[['airline_sentiment_confidence','airline','text','latitude','longitude']]\n",
        "Ydata = data['airline_sentiment']"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "tS7yy8esUQtd",
        "outputId": "f92ba218-2527-41d3-a495-fd4179f7667b"
      },
      "source": [
        "Xdata.head(10)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>airline_sentiment_confidence</th>\n",
              "      <th>airline</th>\n",
              "      <th>text</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.6986</td>\n",
              "      <td>Southwest</td>\n",
              "      <td>@SouthwestAir @love_dragonss oh my god LAUREN ...</td>\n",
              "      <td>46.709294</td>\n",
              "      <td>-97.337366</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0000</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>@VirginAmerica thank goodness!! Also, see you ...</td>\n",
              "      <td>41.411314</td>\n",
              "      <td>-119.153471</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0000</td>\n",
              "      <td>United</td>\n",
              "      <td>@united Resolved. Over hour of work on  ground...</td>\n",
              "      <td>37.626267</td>\n",
              "      <td>-119.172956</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0000</td>\n",
              "      <td>US Airways</td>\n",
              "      <td>@USAirways ok thank you! Very helpful! This is...</td>\n",
              "      <td>40.758600</td>\n",
              "      <td>-73.973100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.6669</td>\n",
              "      <td>Delta</td>\n",
              "      <td>@JetBlue thanks...</td>\n",
              "      <td>35.846756</td>\n",
              "      <td>-98.168765</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.0000</td>\n",
              "      <td>Delta</td>\n",
              "      <td>@JetBlue thanks so much for your condolences a...</td>\n",
              "      <td>39.383085</td>\n",
              "      <td>-99.074612</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.7139</td>\n",
              "      <td>Delta</td>\n",
              "      <td>@JetBlue #flyfi thank you! Seattle and #UDUB h...</td>\n",
              "      <td>38.308253</td>\n",
              "      <td>-98.744859</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1.0000</td>\n",
              "      <td>Southwest</td>\n",
              "      <td>@SouthwestAir Left my computer on the plane. T...</td>\n",
              "      <td>43.487804</td>\n",
              "      <td>-94.652825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1.0000</td>\n",
              "      <td>Southwest</td>\n",
              "      <td>@SouthwestAir THANK YOU for finally making you...</td>\n",
              "      <td>43.487754</td>\n",
              "      <td>-100.334976</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.6867</td>\n",
              "      <td>Southwest</td>\n",
              "      <td>@SouthwestAir @Imaginedragons @beatsmusic well...</td>\n",
              "      <td>39.736510</td>\n",
              "      <td>-101.519388</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   airline_sentiment_confidence         airline  ...   latitude   longitude\n",
              "0                        0.6986       Southwest  ...  46.709294  -97.337366\n",
              "1                        1.0000  Virgin America  ...  41.411314 -119.153471\n",
              "2                        1.0000          United  ...  37.626267 -119.172956\n",
              "3                        1.0000      US Airways  ...  40.758600  -73.973100\n",
              "4                        0.6669           Delta  ...  35.846756  -98.168765\n",
              "5                        1.0000           Delta  ...  39.383085  -99.074612\n",
              "6                        0.7139           Delta  ...  38.308253  -98.744859\n",
              "7                        1.0000       Southwest  ...  43.487804  -94.652825\n",
              "8                        1.0000       Southwest  ...  43.487754 -100.334976\n",
              "9                        0.6867       Southwest  ...  39.736510 -101.519388\n",
              "\n",
              "[10 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "pGICpIILUU6K",
        "outputId": "23e3a5c2-b77a-4fca-e5bf-3f4875e3efa7"
      },
      "source": [
        "Ydata = Ydata.to_frame()\n",
        "Ydata.head(2)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>airline_sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  airline_sentiment\n",
              "0          positive\n",
              "1          positive"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPHHQXTgYm37"
      },
      "source": [
        "most_common = 20000 #number of vocabs to be considered for the embedding matrix\n",
        "max_len = 100 \n",
        "epochs = 10\n",
        "embed_dim = 100\n",
        "batch_size = 100"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Nr5UJRRtJaR"
      },
      "source": [
        "#Function to create word embeddings\n",
        "\n",
        "- we use pre-trained glove model to create word2vec \n",
        "- create a embedding matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMz97Spar0Ve"
      },
      "source": [
        "from utilsfunction  import dataPreprocessing"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Aeb4pDSsiQx",
        "outputId": "7b4cc25a-93c9-46e1-ccaa-71c0f5932f0e"
      },
      "source": [
        "em, X, y, num = dataPreprocessing(Xdata,Ydata, most_common=most_common, max_len= max_len, embed_dim=embed_dim)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 10412 unique tokens.\n",
            "\n",
            "\n",
            " Labels:  ['positive', 'neutral', 'negative']\n",
            "airline_sentiment\n",
            "positive             2363\n",
            "neutral              2363\n",
            "negative             2363\n",
            "dtype: int64\n",
            "  airline_sentiment  label\n",
            "0          positive      1\n",
            "1          positive      1\n",
            "[[0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]]\n",
            "Text 1:  @SouthwestAir @love_dragonss oh my god LAUREN OH MY GOD OH MY GOD\n",
            "Text 1 converted to word index sequences:  [11, 85, 1154, 340, 13, 1087, 1375, 340, 13, 1087, 340, 13, 1087]\n",
            "Text 1 word to padded index sequence of length 100: \n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0   11   85 1154  340   13 1087 1375  340   13 1087  340\n",
            "   13 1087]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JunXx8SgWrRn"
      },
      "source": [
        "#Creating the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYUO6PInuP1l"
      },
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import GlobalMaxPooling1D, Dropout\n",
        "from tensorflow.keras.layers import LSTM, Bidirectional\n",
        "from tensorflow.keras.layers import Dense, Lambda, Dot, Activation, Concatenate\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D,GlobalMaxPool1D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import  SGD, Adam"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFXm0xqiWtnj"
      },
      "source": [
        "#creating the embedding layer\n",
        "embedding_layer = Embedding(input_dim=num,output_dim=max_len,weights=[em],input_length=max_len,trainable=False)\n",
        "#input_layer\n",
        "input_layer = Input((max_len,),name='InputLayer')\n",
        "#embedding layer\n",
        "embedding_layer = embedding_layer(input_layer)\n",
        "#bi-directional LSTM layer\n",
        "lstm = Bidirectional(LSTM(50,return_sequences=True))(embedding_layer)\n",
        "#dropout layer\n",
        "drop_lstm = Dropout(0.3)(lstm)\n",
        "#CNN layers\n",
        "first_conv_layer = Conv1D(128, 3, activation='relu')(lstm)\n",
        "first_max_pooling_layer = MaxPooling1D(3)(first_conv_layer)\n",
        "second_conv_layer = Conv1D(128, 4, activation='relu')(first_conv_layer)\n",
        "second_max_pooling_layer = MaxPooling1D(4)(second_conv_layer)\n",
        "third_conv_layer = Conv1D(128, 5, activation='relu')(second_max_pooling_layer)\n",
        "third_max_pooling_layer = MaxPooling1D(5)(third_conv_layer)\n",
        "merged = Concatenate(axis=1)([first_max_pooling_layer,second_max_pooling_layer,third_max_pooling_layer])\n",
        "context_vector = GlobalMaxPool1D()(merged)\n",
        "\n",
        "#attention mechanism\n",
        "densor1 = Dense(10, activation = \"tanh\")\n",
        "densor2 = Dense(100, activation = \"relu\")\n",
        "activator = Activation('softmax', name='attention_weights')\n",
        "dotor = Dot(axes = 1)\n",
        "hidden_size = int(lstm.shape[2])\n",
        "h_t = Lambda(lambda x: x[:, -1, :], output_shape=(hidden_size,), name='last_hidden_state')(lstm)\n",
        "pre_activation = Concatenate(axis=1)([context_vector, h_t])\n",
        "e = densor1(pre_activation)\n",
        "energies = densor2(e)\n",
        "alphas = activator(energies)\n",
        "s = dotor([alphas, lstm])\n",
        "\n",
        "#hidden_size = int(lstm.shape[2])\n",
        "#h_t = Lambda(lambda x: x[:, -1, :], output_shape=(hidden_size,), name='last_hidden_state')(lstm)\n",
        "#pre_activation = Concatenate(axis=1)([merged_vector, h_t])\n",
        "output_layer = Dense(3, use_bias=False, activation='softmax', name='attention_vector')(s)\n",
        "model = Model(input_layer,output_layer)\n",
        "model.compile(\n",
        "        loss='categorical_crossentropy',\n",
        "        optimizer=Adam(learning_rate=0.01),\n",
        "        metrics=['accuracy']\n",
        "             )"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pKC_3LKJ3Sd"
      },
      "source": [
        "#splitting the data as 80 : 20\n",
        "# 80% for training and 20% for testing\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_dOrK4NLN8D"
      },
      "source": [
        "import tensorflow"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aS9vUSUE0GSU",
        "outputId": "03ffb1d8-c89b-40f9-e2ff-0bd8cc612e46"
      },
      "source": [
        "from tensorflow.keras.callbacks import Callback\n",
        "\n",
        "class MyThresholdCallback(tensorflow.keras.callbacks.Callback):\n",
        "    def __init__(self, threshold):\n",
        "        super(MyThresholdCallback, self).__init__()\n",
        "        self.threshold = threshold\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None): \n",
        "        acc = logs[\"accuracy\"]\n",
        "        if acc >= self.threshold:\n",
        "            self.model.stop_training = True\n",
        "\n",
        "\n",
        "callback=MyThresholdCallback(threshold=0.88)\n",
        "r = model.fit(\n",
        "            X_train,\n",
        "            y_train,\n",
        "            batch_size=50,\n",
        "            epochs=200,\n",
        "            validation_split=0.2,\n",
        "            callbacks=[callback]  \n",
        "            )\n",
        "\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "91/91 [==============================] - 20s 219ms/step - loss: 0.6496 - accuracy: 0.7262 - val_loss: 0.7019 - val_accuracy: 0.7110\n",
            "Epoch 2/200\n",
            "91/91 [==============================] - 20s 216ms/step - loss: 0.5628 - accuracy: 0.7705 - val_loss: 0.6888 - val_accuracy: 0.7093\n",
            "Epoch 3/200\n",
            "91/91 [==============================] - 20s 218ms/step - loss: 0.4744 - accuracy: 0.8186 - val_loss: 0.6889 - val_accuracy: 0.7101\n",
            "Epoch 4/200\n",
            "91/91 [==============================] - 20s 217ms/step - loss: 0.3934 - accuracy: 0.8459 - val_loss: 0.7701 - val_accuracy: 0.7119\n",
            "Epoch 5/200\n",
            "91/91 [==============================] - 20s 216ms/step - loss: 0.3053 - accuracy: 0.8862 - val_loss: 0.8335 - val_accuracy: 0.7137\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZpFf0vPT0Ova",
        "outputId": "66a6743a-6a82-47e3-dd6e-71d9020b0de3"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "InputLayer (InputLayer)         [(None, 100)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_3 (Embedding)         (None, 100, 100)     1041300     InputLayer[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional (Bidirectional)   (None, 100, 100)     60400       embedding_3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d (Conv1D)                 (None, 98, 128)      38528       bidirectional[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_1 (Conv1D)               (None, 95, 128)      65664       conv1d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1D)  (None, 23, 128)      0           conv1d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_2 (Conv1D)               (None, 19, 128)      82048       max_pooling1d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D)    (None, 32, 128)      0           conv1d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1D)  (None, 3, 128)       0           conv1d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 58, 128)      0           max_pooling1d[0][0]              \n",
            "                                                                 max_pooling1d_1[0][0]            \n",
            "                                                                 max_pooling1d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d (GlobalMax (None, 128)          0           concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "last_hidden_state (Lambda)      (None, 100)          0           bidirectional[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 228)          0           global_max_pooling1d[0][0]       \n",
            "                                                                 last_hidden_state[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           2290        concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 100)          1100        dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "attention_weights (Activation)  (None, 100)          0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dot (Dot)                       (None, 100)          0           attention_weights[0][0]          \n",
            "                                                                 bidirectional[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "attention_vector (Dense)        (None, 3)            300         dot[0][0]                        \n",
            "==================================================================================================\n",
            "Total params: 1,291,630\n",
            "Trainable params: 250,330\n",
            "Non-trainable params: 1,041,300\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAbo6O8f0RtR"
      },
      "source": [
        "model.save(\"bilstmCNNAtt.h5\")"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zXub27LoTSP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}